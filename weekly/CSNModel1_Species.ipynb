{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSN Modelling: Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, KFold\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fitted(true_value, predicted_value, title, save_path):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.scatter(true_value, predicted_value, s=5, c=\"crimson\")\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "\n",
    "    p1 = max(max(predicted_value), max(true_value))\n",
    "    p2 = min(min(predicted_value), min(true_value))\n",
    "    plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "    plt.xlabel('True Values', fontsize=11)\n",
    "    plt.ylabel('Predictions', fontsize=11)\n",
    "    plt.axis('equal')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "def get_perf(mod, preds, X_test, y_test, method):\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_test, preds)), 2)\n",
    "    r2 = round(mod.score(X_test, y_test), 2)\n",
    "    return rmse, r2\n",
    "\n",
    "def plot_imp(mod, feature_list, title, save_path):\n",
    "    # Specify feature names\n",
    "    mod.get_booster().feature_names = feature_list\n",
    "    # Plot in a graph with top 11 features\n",
    "    ax = xgb.plot_importance(mod.get_booster(), max_num_features=10)\n",
    "    plt.tight_layout()\n",
    "    plt.title(title)\n",
    "    ax.figure.savefig(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "csn_misr = pd.read_csv('../data/merged/WithCL_MISR_CSN_2000_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = csn_misr.dropna(subset = ['AOD'])\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data dimension: 5289 observations, 312 features.\n",
      "New data dimension: 1709 observations, 312 features.\n",
      "Percent dropped: 67.69\n"
     ]
    }
   ],
   "source": [
    "percent_dropped = round((1 - (df.shape[0]/csn_misr.shape[0]))*100, 2)\n",
    "print(\"Original data dimension:\",csn_misr.shape[0], \"observations,\", csn_misr.shape[1], \"features.\")\n",
    "print(\"New data dimension:\",df.shape[0], \"observations,\", df.shape[1], \"features.\")\n",
    "print(f\"Percent dropped: {percent_dropped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create year, month variables\n",
    "df['Year'] = pd.DatetimeIndex(df.loc[:, 'Date']).year.astype('category')\n",
    "df['Month'] = pd.DatetimeIndex(df.loc[:, 'Date']).month.astype('category')\n",
    "\n",
    "# Cast other categorical variables to the right type\n",
    "\n",
    "for col in ['POC', 'Site.Code', 'light', 'med', 'heavy', 'ecosys']:\n",
    "    df[col] = df.loc[:, col].astype('category')\n",
    "\n",
    "# Replace NAs in smoke vars with 0\n",
    "df['light'].fillna(0, inplace=True)\n",
    "df['med'].fillna(0, inplace=True)\n",
    "df['heavy'].fillna(0, inplace=True)\n",
    "df['ecosys'].cat.add_categories(-1).fillna(-1)\n",
    "\n",
    "# Replace NAs in cluster info vars with 0\n",
    "df['frp_avg'].fillna(-999, inplace=True)\n",
    "df['frp_vars'].fillna(-999, inplace=True)\n",
    "df['num_pts'].fillna(0, inplace=True)\n",
    "\n",
    "# First type: create quantiles for fire distance; placeholder \"x+1\"th quantile for NAs\n",
    "df['fire_dist_25'] = pd.qcut(df['fire_dist'], q=[0, .25, .5, .75, 1.], labels=[1,2,3,4])\n",
    "df['fire_dist_25'] = df['fire_dist_25'].cat.add_categories(5)\n",
    "df['fire_dist_25'].fillna(5, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in ['Al', 'Si', 'Ca', 'Ti', 'Fe']:\n",
    "    df[el].fillna(0, inplace=True)\n",
    "df['dust'] = 2.2*df['Al'] + 2.49*df['Si'] + 1.63*df['Ca'] + 1.94*df['Ti'] + 2.42*df['Fe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dust'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling for Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_FEATS = {'none': [], 'aod_only':['AOD'], 'raw_aod_etc':['AOD', 'AOD_absorption', 'AOD_nonspherical', 'small_mode_AOD', \\\n",
    "    'medium_mode_AOD', 'large_mode_AOD'], 'aod_mix':['aod_mix_01', 'aod_mix_02', 'aod_mix_03', 'aod_mix_04', \\\n",
    "    'aod_mix_05', 'aod_mix_06', 'aod_mix_07', 'aod_mix_08', 'aod_mix_09', 'aod_mix_10', 'aod_mix_11', 'aod_mix_12', \\\n",
    "    'aod_mix_13', 'aod_mix_14', 'aod_mix_15', 'aod_mix_16', 'aod_mix_17', 'aod_mix_18', 'aod_mix_19', 'aod_mix_20', \\\n",
    "    'aod_mix_21', 'aod_mix_22', 'aod_mix_23', 'aod_mix_24', 'aod_mix_25', 'aod_mix_26', 'aod_mix_27', 'aod_mix_28', \\\n",
    "    'aod_mix_29', 'aod_mix_30', 'aod_mix_31', 'aod_mix_32', 'aod_mix_33', 'aod_mix_34', 'aod_mix_35', 'aod_mix_36', \\\n",
    "    'aod_mix_37', 'aod_mix_38', 'aod_mix_39', 'aod_mix_40', 'aod_mix_41', 'aod_mix_42', 'aod_mix_43', 'aod_mix_44', \\\n",
    "    'aod_mix_45', 'aod_mix_46', 'aod_mix_47', 'aod_mix_48', 'aod_mix_49', 'aod_mix_50', 'aod_mix_51', 'aod_mix_52', \\\n",
    "    'aod_mix_53', 'aod_mix_54', 'aod_mix_55', 'aod_mix_56', 'aod_mix_57', 'aod_mix_58', 'aod_mix_59', 'aod_mix_60', \\\n",
    "    'aod_mix_61', 'aod_mix_62', 'aod_mix_63', 'aod_mix_64', 'aod_mix_65', 'aod_mix_66', 'aod_mix_67', 'aod_mix_68', \\\n",
    "    'aod_mix_69', 'aod_mix_70', 'aod_mix_71', 'aod_mix_72', 'aod_mix_73', 'aod_mix_74']}\n",
    "MODEL_FEATS = {}\n",
    "EXP_NAME = {'none': 'No AOD', 'aod_only': 'AOD Only', 'raw_aod_etc': 'Raw AOD & etc.', 'aod_mix': 'AOD Mix'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(df, y, feature_list, test_size, exp_type, outf, dir):\n",
    "    one_hot = pd.get_dummies(df[feature_list], columns = ['POC', 'fire_dist_25'])\n",
    "    X_one_hot = np.array(one_hot)\n",
    "    MODEL_FEATS[exp_type] = list(one_hot.columns)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_one_hot, y, test_size = 0.3, random_state = 88)\n",
    "    xgb_mod = xgb.XGBRegressor(objective=\"reg:squarederror\", subsample=1.0, min_child_weight=1, max_depth=10, gamma=1.5, colsample_bytree=1.0, random_state=88)\n",
    "    xgb_mod.fit(X_train, y_train)\n",
    "    preds_xgb = xgb_mod.predict(X_test)\n",
    "    rmse, r2 = get_perf(xgb_mod, preds_xgb, X_test, y_test, exp_type)\n",
    "\n",
    "    outf.write(f'---- Experiment type: {EXP_NAME[exp_type]} ----\\n')\n",
    "    outf.write(f'Training Features Shape: {X_train.shape}\\n')\n",
    "    outf.write(f'Training Labels Shape: {y_train.shape}\\n')\n",
    "    outf.write(f'Testing Features Shape: {X_test.shape}\\n')\n",
    "    outf.write(f'Testing Labels Shape: {y_test.shape}\\n')\n",
    "    outf.write(f'-- Performance --\\n')\n",
    "    outf.write(f'RMSE: {rmse}\\n')\n",
    "    outf.write(f'R2: {r2}\\n')\n",
    "    ft_img_name = \"ft-imp_\" + exp_type + \".png\"\n",
    "    fitted_name = \"pred-true_\" + exp_type + \".png\"\n",
    "    plot_imp(xgb_mod, MODEL_FEATS[exp_type], \"Feature importance: \" + EXP_NAME[exp_type], os.path.join(dir, ft_img_name))\n",
    "    plot_fitted(y_test, preds_xgb, \"Pred vs True: \" + EXP_NAME[exp_type], os.path.join(dir, fitted_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_features = ['Year', 'Month', 'POC', 'Site.Latitude', 'Site.Longitude', \\\n",
    "    'elevation', 'fire_dist_25', 'light', 'med', 'heavy','frp_avg', 'frp_vars', \\\n",
    "    'num_pts', 'ecosys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"model_results.txt\", \"w\") as outf:\n",
    "    for sp in ['sulfate', 'nitrate', 'dust', 'EC_unadjusted', 'OC']:\n",
    "        df[sp].fillna(0, inplace=True)\n",
    "        labels = np.array(df[sp])\n",
    "        outf.write(f'****** Species: {sp} ******\\n')\n",
    "        img_dir_path = os.path.join(\"../img/\", sp)\n",
    "        if not os.path.exists(img_dir_path):\n",
    "            os.mkdir(img_dir_path)\n",
    "        for exp_type in ADD_FEATS.keys():\n",
    "            ft_lst = subset_features + ADD_FEATS[exp_type]\n",
    "            run_exp(df, labels, ft_lst, 0.3, exp_type, outf, img_dir_path)\n",
    "        outf.write(f'================================================\\n')\n",
    "outf.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold(df, y, feature_list, test_size, exp_type, outf, dir):\n",
    "    one_hot = pd.get_dummies(df[feature_list], columns = ['POC', 'fire_dist_25'])\n",
    "    X_one_hot = np.array(one_hot)\n",
    "    MODEL_FEATS[exp_type] = list(one_hot.columns)\n",
    "    kf = KFold(n_splits=5)\n",
    "    rmse_lst = []\n",
    "    r2_lst = []\n",
    "    for i, (train_ind, test_ind) in enumerate(kf.split(X_one_hot,y)):\n",
    "        X_train = X_one_hot[train_ind]\n",
    "        X_test = X_one_hot[test_ind]\n",
    "        y_train = y[train_ind]\n",
    "        y_test = y[test_ind]\n",
    "        xgb_mod = xgb.XGBRegressor(objective=\"reg:squarederror\", subsample=1.0, min_child_weight=1, max_depth=10, gamma=1.5, colsample_bytree=1.0, random_state=88)\n",
    "        xgb_mod.fit(X_train, y_train)\n",
    "        preds_xgb = xgb_mod.predict(X_test)\n",
    "        rmse, r2 = get_perf(xgb_mod, preds_xgb, X_test, y_test, exp_type)\n",
    "        rmse_lst.append(rmse)\n",
    "        r2_lst.append(r2)\n",
    "        # ft_img_name = \"ft-imp_\" + exp_type + \".png\"\n",
    "        # fitted_name = \"pred-true_\" + exp_type + \".png\"\n",
    "        # plot_imp(xgb_mod, MODEL_FEATS[exp_type], \"Feature importance: \" + EXP_NAME[exp_type], os.path.join(dir, ft_img_name))\n",
    "        # plot_fitted(y_test, preds_xgb, \"Pred vs True: \" + EXP_NAME[exp_type], os.path.join(dir, fitted_name))\n",
    "    outf.write(f'---- Experiment type: {EXP_NAME[exp_type]} ----\\n')\n",
    "    outf.write(f'Obs/Fold in Train: {len(train_ind)}\\n')\n",
    "    outf.write(f'Obs/Fold in Test: {len(test_ind)}\\n')\n",
    "    outf.write(f'-- Performance --\\n')\n",
    "    outf.write(f'RMSE: {sum(rmse_lst)/len(rmse_lst)}\\n')\n",
    "    outf.write(f'R2: {sum(r2_lst)/len(r2_lst)}\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dx/vf7v90ms0yddzdx3cv6z9lkr0000gn/T/ipykernel_75309/2021608947.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[sp].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "with open(f\"model_kfold_results.txt\", \"w\") as outf:\n",
    "    sp = 'dust'\n",
    "    df[sp].fillna(0, inplace=True)\n",
    "    labels = np.array(df[sp])\n",
    "    outf.write(f'****** Species: {sp} ******\\n')\n",
    "    img_dir_path = os.path.join(\"../img/\", sp)\n",
    "    if not os.path.exists(img_dir_path):\n",
    "        os.mkdir(img_dir_path)\n",
    "    for exp_type in ADD_FEATS.keys():\n",
    "        ft_lst = subset_features + ADD_FEATS[exp_type]\n",
    "        run_kfold(df, labels, ft_lst, 0.3, exp_type, outf, img_dir_path)\n",
    "    outf.write(f'================================================\\n')\n",
    "outf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EC (Elemental Carbon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = np.array(df['EC_unadjusted'])\n",
    "labels2 = np.array(df['EC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAs in EC:  4091\n",
      "NAs in EC_unadj:  2193\n"
     ]
    }
   ],
   "source": [
    "print(\"NAs in EC: \", csn_misr['EC'].isnull().sum())\n",
    "print(\"NAs in EC_unadj: \", csn_misr['EC_unadjusted'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_ec = csn_misr['EC'].index[csn_misr['EC'].apply(np.isnan)]\n",
    "ind_unadj = csn_misr['EC_unadjusted'].index[csn_misr['EC_unadjusted'].apply(np.isnan)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13588691290469676"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Difference in NAs for EC & EC_unadj\n",
    "len(set(ind_unadj) - set(ind_ec))/len(set(ind_unadj))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
