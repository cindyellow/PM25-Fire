{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, KFold\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for each experiment type \n",
    "# (i.e. if experimenting with AOD products, then additional features corresponding to ADD_FEATS['aod_prod'] are included.)\n",
    "ADD_FEATS = {'none': [], 'aod_only':['AOD'], 'aod_prod':['AOD_absorption', 'AOD_nonspherical', 'small_mode_AOD', \\\n",
    "    'medium_mode_AOD', 'large_mode_AOD'], 'aod_mix':['aod_mix_01', 'aod_mix_02', 'aod_mix_03', 'aod_mix_04', \\\n",
    "    'aod_mix_05', 'aod_mix_06', 'aod_mix_07', 'aod_mix_08', 'aod_mix_09', 'aod_mix_10', 'aod_mix_11', 'aod_mix_12', \\\n",
    "    'aod_mix_13', 'aod_mix_14', 'aod_mix_15', 'aod_mix_16', 'aod_mix_17', 'aod_mix_18', 'aod_mix_19', 'aod_mix_20', \\\n",
    "    'aod_mix_21', 'aod_mix_22', 'aod_mix_23', 'aod_mix_24', 'aod_mix_25', 'aod_mix_26', 'aod_mix_27', 'aod_mix_28', \\\n",
    "    'aod_mix_29', 'aod_mix_30', 'aod_mix_31', 'aod_mix_32', 'aod_mix_33', 'aod_mix_34', 'aod_mix_35', 'aod_mix_36', \\\n",
    "    'aod_mix_37', 'aod_mix_38', 'aod_mix_39', 'aod_mix_40', 'aod_mix_41', 'aod_mix_42', 'aod_mix_43', 'aod_mix_44', \\\n",
    "    'aod_mix_45', 'aod_mix_46', 'aod_mix_47', 'aod_mix_48', 'aod_mix_49', 'aod_mix_50', 'aod_mix_51', 'aod_mix_52', \\\n",
    "    'aod_mix_53', 'aod_mix_54', 'aod_mix_55', 'aod_mix_56', 'aod_mix_57', 'aod_mix_58', 'aod_mix_59', 'aod_mix_60', \\\n",
    "    'aod_mix_61', 'aod_mix_62', 'aod_mix_63', 'aod_mix_64', 'aod_mix_65', 'aod_mix_66', 'aod_mix_67', 'aod_mix_68', \\\n",
    "    'aod_mix_69', 'aod_mix_70', 'aod_mix_71', 'aod_mix_72', 'aod_mix_73', 'aod_mix_74']}\n",
    "MODEL_FEATS = {}\n",
    "EXP_NAME = {'none': 'No AOD', 'aod_only': 'AOD Only', 'aod_prod': 'AOD Products', 'aod_mix': 'AOD Mix'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(df):\n",
    "    # Create year, month variables\n",
    "    df['Year'] = pd.DatetimeIndex(df.loc[:, 'Date']).year.astype('category')\n",
    "    df['Month'] = pd.DatetimeIndex(df.loc[:, 'Date']).month.astype('category')\n",
    "\n",
    "    # Cast other categorical variables to the right type\n",
    "    for col in ['POC', 'Site.Code', 'light', 'med', 'heavy', 'ecosys']:\n",
    "        df[col] = df.loc[:, col].astype('category')\n",
    "\n",
    "    # Replace NAs in smoke vars with 0\n",
    "    df['light'].fillna(0, inplace=True)\n",
    "    df['med'].fillna(0, inplace=True)\n",
    "    df['heavy'].fillna(0, inplace=True)\n",
    "    df['ecosys'] = df['ecosys'].cat.add_categories(-1)\n",
    "    df['ecosys'].fillna(-1, inplace=True)\n",
    "\n",
    "    # Replace NAs in cluster info vars with 0\n",
    "    df['frp_avg'].fillna(-999, inplace=True)\n",
    "    df['frp_vars'].fillna(-999, inplace=True)\n",
    "    df['num_pts'].fillna(0, inplace=True)\n",
    "\n",
    "    # First type: create quantiles for fire distance; placeholder \"x+1\"th quantile for NAs\n",
    "    df['fire_dist_25'] = pd.qcut(df['fire_dist'], q=[0, .25, .5, .75, 1.], labels=[1,2,3,4])\n",
    "    df['fire_dist_25'] = df['fire_dist_25'].cat.add_categories(5)\n",
    "    df['fire_dist_25'].fillna(5, inplace=True)\n",
    "    \n",
    "    # Continuous variable that fills NAs of fire_dist with the maximum fire distance + 10\n",
    "    max_fire = df['fire_dist'].max()\n",
    "    df['fire_dist_rep-max'] = df['fire_dist'].fillna(max_fire+10)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X, X_test, X_imp=None, y=None, one_hot_cols=[], scaler=StandardScaler(), split=False, exp_type=None):\n",
    "    \"\"\"\n",
    "    Transform X and y (optional) using scaler. If split is True, then the test set is not provided and train_test_split\n",
    "    is performed. If X_imp is not None, we also transform imputed data using the same scaler.\n",
    "    \n",
    "    Returns the transformed X_train, X_test, X_imp, y_train, y_test\n",
    "    \"\"\"\n",
    "    # One-hot code categorical variables\n",
    "    X_oh = pd.get_dummies(X, columns = one_hot_cols)\n",
    "    # Save features of exp_type in MODEL_FEATS\n",
    "    if exp_type is not None:\n",
    "        MODEL_FEATS[exp_type] = list(X_oh.columns)\n",
    "    X_arr = np.array(X_oh)\n",
    "    cont_col = X_oh.select_dtypes(include=[np.float64, np.int64]).columns\n",
    "    cont_ind = [X_oh.columns.get_loc(c) for c in cont_col]\n",
    "    if not split:\n",
    "        # X_test provided explicitly\n",
    "        X_arr[:,cont_ind] = scaler.fit_transform(X_arr[:,cont_ind])\n",
    "        X_test_oh = pd.get_dummies(X_test, columns = one_hot_cols)\n",
    "        X_test_arr = np.array(X_test_oh)\n",
    "        X_test_arr[:,cont_ind] = scaler.transform(X_test_arr[:,cont_ind])\n",
    "        X_train_arr, y_train, y_test = X_arr, None, None\n",
    "\n",
    "    else:\n",
    "        # split data first\n",
    "        X_train_arr, X_test_arr, y_train, y_test = train_test_split(X_arr, y, test_size = 0.3, random_state = 88)\n",
    "        # fit scaler on training data\n",
    "        X_train_arr[:,cont_ind] = scaler.fit_transform(X_train_arr[:,cont_ind])\n",
    "        X_test_arr[:,cont_ind] = scaler.transform(X_test_arr[:,cont_ind])\n",
    "    \n",
    "    X_imp_arr = None\n",
    "    \n",
    "    if X_imp is not None:\n",
    "        X_imp_oh = pd.get_dummies(X_imp, columns = one_hot_cols)\n",
    "        X_imp_arr = np.array(X_imp_oh)\n",
    "        X_imp_arr[:,cont_ind] = scaler.transform(X_imp_arr[:,cont_ind])    \n",
    "\n",
    "    return X_train_arr, X_test_arr, X_imp_arr, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fitted(true_value, predicted_value, title, save_path):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.scatter(true_value, predicted_value, s=5, c=\"crimson\")\n",
    "\n",
    "    p1 = max(max(predicted_value), max(true_value))\n",
    "    p2 = min(min(predicted_value), min(true_value))\n",
    "    plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "    plt.xlabel('True Values', fontsize=11)\n",
    "    plt.ylabel('Predictions', fontsize=11)\n",
    "    plt.axis('equal')\n",
    "\n",
    "    m, b = np.polyfit(true_value, predicted_value, deg=1)\n",
    "    plt.axline(xy1=(0, b), slope=m, label=f'$y = {m:.1f}x {b:+.1f}$')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "def get_perf(y_test, preds):\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_test, preds)), 2)\n",
    "    r2 = round(r2_score(y_test, preds),2)\n",
    "    return rmse, r2\n",
    "\n",
    "def get_perf_df(df, sp, exp_type):\n",
    "    rmse = round(np.sqrt(mean_squared_error(df['actual'], df['predicted'])), 2)\n",
    "    r2 = round(r2_score(df['actual'], df['predicted']),2)\n",
    "    return pd.Series(dict(species=sp, exp_type=exp_type, r2 = r2, rmse = rmse))\n",
    "\n",
    "def plot_imp(mod, feature_list, title, save_path):\n",
    "    # Specify feature names (for XGBoost)\n",
    "    # mod.get_booster().feature_names = feature_list\n",
    "    # Plot in a graph with top 11 features\n",
    "    # ax = xgb.plot_importance(mod.get_booster(), max_num_features=10, importance_type='gain')\n",
    "    # ax.figure.savefig(save_path)\n",
    "    \n",
    "    importances = mod.feature_importances_\n",
    "    sorted_idx = importances.argsort()[::-1][:10][::-1]\n",
    "    plt.barh(np.array(feature_list)[sorted_idx], importances[sorted_idx])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.title(title)\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "def create_comp_plot(df, cat, t1, t2):\n",
    "    #create catplot\n",
    "    g = sns.catplot(data=df, x='species', y='r2', col='model', hue=cat, kind=\"bar\")\n",
    "\n",
    "    #move overall title up\n",
    "    g.fig.subplots_adjust(top=.8)\n",
    "\n",
    "    #add overall title\n",
    "    g.set(xlabel=\"Species\", ylabel=\"r2\")\n",
    "    g.set_titles(\"{col_name}\")\n",
    "    g.fig.suptitle(t1)\n",
    "    g.set(ylim=(-1, 1))\n",
    "\n",
    "    #create catplot\n",
    "    g = sns.catplot(data=df, x='species', y='rmse', col='model', hue=cat, kind=\"bar\")\n",
    "\n",
    "    #move overall title up\n",
    "    g.fig.subplots_adjust(top=.8)\n",
    "\n",
    "    #add overall title\n",
    "    g.set(xlabel=\"Species\", ylabel=\"rmse\")\n",
    "    g.set_titles(\"{col_name}\")\n",
    "    g.set(ylim=(0, None))\n",
    "    g.fig.suptitle(t2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csn_misr = pd.read_csv('../data/merged/MergedAll_MISR_CSN_2000_2021.csv')\n",
    "aod_df = preproc(csn_misr.copy())\n",
    "aod_nonNA = aod_df.dropna(subset = ['AOD'])\n",
    "aod_NA = aod_df[aod_df['AOD'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_FEATURES = ['Year', 'Month', 'POC', 'Site.Latitude', 'Site.Longitude', \\\n",
    "    'elevation', 'fire_dist_rep-max', 'light', 'med', 'heavy','frp_avg', 'frp_vars', \\\n",
    "    'num_pts', 'ecosys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_knn(df, impute_ft):\n",
    "    \"\"\"\n",
    "    Impute the features impute_ft for dataframe df.\n",
    "\n",
    "    Returns the imputed copy of the df and indices where features have been imputed.\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    imp_ind = []\n",
    "    for var in impute_ft:\n",
    "        df_nonNA = df.dropna(subset = [var])\n",
    "        df_NA = df[df[var].isna()]\n",
    "        imp_ind.extend(list(df_NA.index))\n",
    "        if df_NA.empty:\n",
    "            continue\n",
    "        X = df_nonNA.loc[:,KNN_FEATURES]\n",
    "        y = df_nonNA.loc[:,'AOD']\n",
    "        X_test = df_NA.loc[:,KNN_FEATURES]\n",
    "        print(\"Non-NAs: {} \\nNAs: {}\".format(X.shape[0], X_test.shape[0]))\n",
    "        \n",
    "        X_train_oh, X_test_oh, _, _, _ = transform(X, X_test, one_hot_cols = ['POC', 'ecosys'])\n",
    "        knn = KNeighborsRegressor(n_neighbors=10,weights='distance')\n",
    "        knn.fit(X_train_oh, y)\n",
    "        preds_knn = knn.predict(X_test_oh)\n",
    "\n",
    "        print(\"Training RMSE & R2:\", get_perf(y, knn.predict(X_train_oh)))\n",
    "        print(\"Total values interpolated [{}] : {}\".format(var, preds_knn.shape[0]))\n",
    "        preds_knn = pd.Series(preds_knn, index = df_NA.index)\n",
    "        new_df[var].fillna(preds_knn, inplace=True)\n",
    "    return new_df, imp_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp_aod, aod_imp_ind = impute_knn(aod_df, ['AOD'])\n",
    "df_imp_aod.to_csv(\"../data/imputed/misr-csn_aod-only_imputed.csv\", index=False)\n",
    "\n",
    "aod_prod = ['AOD_absorption', 'AOD_nonspherical', 'small_mode_AOD', 'medium_mode_AOD', 'large_mode_AOD']\n",
    "df_imp_prod, prod_imp_ind = impute_knn(aod_df, aod_prod)\n",
    "df_imp_prod.to_csv(\"../data/imputed/misr-csn_aod-prod_imputed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_base(df_nonNA, df_NA_imp, feature_list, res_base):\n",
    "    \"\"\"\n",
    "    We train a base model with feature_list on df_nonNA (df with nonNA AOD vars) and \n",
    "    test performance on df_NA_imp (df with solely imputed NA AOD vars). Results\n",
    "    are recorded in res_base and res_imp.\n",
    "    \"\"\"\n",
    "    for sp in ['sulfate', 'nitrate', 'dust', 'EC', 'OC']:\n",
    "        if sp == 'dust':\n",
    "            df_new = df_nonNA.dropna(subset = ['Al', 'Si', 'Ca', 'Ti', 'Fe'] + feature_list)\n",
    "            df_new['dust'] = 2.2*df_new['Al'] + 2.49*df_new['Si'] + 1.63*df_new['Ca'] + 1.94*df_new['Ti'] + 2.42*df_new['Fe']\n",
    "            df_imp = df_NA_imp.dropna(subset = ['Al', 'Si', 'Ca', 'Ti', 'Fe'] + feature_list)\n",
    "            df_imp['dust'] = 2.2*df_NA_imp['Al'] + 2.49*df_NA_imp['Si'] + 1.63*df_NA_imp['Ca'] + 1.94*df_NA_imp['Ti'] + 2.42*df_NA_imp['Fe']\n",
    "        else:\n",
    "            df_new = df_nonNA.dropna(subset = [sp] + feature_list)\n",
    "            df_imp = df_NA_imp.dropna(subset = [sp] + feature_list)\n",
    "        ## HANDLE OUTLIERS ##\n",
    "        outlier_cutoff = 3 * np.percentile(df_new[sp], 75)\n",
    "        imp_outlier_cutoff = 3 * np.percentile(df_imp[sp], 75)\n",
    "        num_non, imp_num_non = df_new.shape[0], df_imp.shape[0]\n",
    "        df_new = df_new[df_new[sp] <= outlier_cutoff]\n",
    "        df_imp = df_imp[df_imp[sp] <= imp_outlier_cutoff]\n",
    "        print('Outliers removed: ', num_non-df_new.shape[0], imp_num_non-df_imp.shape[0])\n",
    "        print('Cutoff: ', outlier_cutoff, imp_outlier_cutoff)\n",
    "        ####\n",
    "        y = np.log(1 + df_new[sp])\n",
    "        y_imp = np.log(1 + df_imp[sp])\n",
    "        # y = df_new[sp]\n",
    "        # y_imp = df_imp[sp]\n",
    "        X_train, X_test, X_imp, y_train, y_test = transform(df_new[feature_list], None, df_imp[feature_list], y, \\\n",
    "            one_hot_cols = ['POC', 'fire_dist_25', 'ecosys'], split=True)\n",
    "        mod = RandomForestRegressor()\n",
    "        mod.fit(X_train, y_train)\n",
    "        preds = mod.predict(X_test)\n",
    "        preds_imp = mod.predict(X_imp)\n",
    "        mod2 = xgb.XGBRegressor(objective=\"reg:squarederror\")\n",
    "        mod2.fit(X_train, y_train)\n",
    "        preds2 = mod2.predict(X_test)\n",
    "        preds2_imp = mod2.predict(X_imp)\n",
    "\n",
    "        # Performance of base model on imputed data\n",
    "        rmse_rf, r2_rf = get_perf(y_imp, preds_imp)\n",
    "        # plot_fitted(y_imp, preds_imp, \"Fitted vs True: \" + sp + \" (RF)\", \"../img/imputed/\" + sp + \"-fitted_rf.png\")\n",
    "        rmse_xg, r2_xg = get_perf(y_imp, preds2_imp)\n",
    "        # plot_fitted(y_imp, preds2_imp, \"Fitted vs True: \" + sp + \" (XGB)\", \"../img/imputed/\" + sp + \"-fitted_xgb.png\")\n",
    "        \n",
    "        res_base = pd.concat([res_base, pd.DataFrame({'species': [sp, sp], 'r2':[r2_rf, r2_xg], 'rmse': [rmse_rf, rmse_xg], \\\n",
    "            'imp_method': ['base', 'base'], 'model': ['rf', 'xgb'], 'test_set': ['imp', 'imp']})])\n",
    "        \n",
    "        # Performance of base model on its own test set\n",
    "        rmse_rf, r2_rf = get_perf(y_test, preds)\n",
    "        # /img/sulfate/ft-imp/\n",
    "        plot_fitted(y_test, preds, \"Fitted vs True: \" + sp + \" (RF)\", \"../img/\" + sp + \"/fitted/\" + sp + \"-fitted_rf.png\")\n",
    "        rmse_xg, r2_xg = get_perf(y_test, preds2)\n",
    "        # plot_fitted(y_test, preds2, \"Fitted vs True: \" + sp + \" (XGB)\", \"../img/imputed/\" + sp + \"-fitted_xgb.png\")\n",
    "\n",
    "        plot_imp(mod, MODEL_FEATS['aod_only'], \"Ft Importance for \" + sp + \" [\" + 'aod_only' + \"]\", \"\".join([\"../img/\", sp, \"/ft-imp/\", sp, \"-\", \"aod_only\", \"-ft_imp_rf.png\"]))\n",
    "\n",
    "        res_base = pd.concat([res_base, pd.DataFrame({'species': [sp, sp], 'r2':[r2_rf, r2_xg], 'rmse': [rmse_rf, rmse_xg], \\\n",
    "            'imp_method': ['base', 'base'], 'model': ['rf', 'xgb'], 'test_set': ['base', 'base']})])\n",
    "        \n",
    "    return res_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_imp(df_imp, feature_list, res_imp, exp_type):\n",
    "    \"\"\"\n",
    "    Train model with feature_list on df_imp (complete df \n",
    "    including imputed data). Record test set results in res_imp.\n",
    "    \"\"\"\n",
    "    for sp in ['sulfate', 'nitrate', 'dust', 'EC', 'OC']:\n",
    "        if sp == 'dust':\n",
    "            df_new = df_imp.dropna(subset = ['Al', 'Si', 'Ca', 'Ti', 'Fe'] + feature_list)\n",
    "            df_new['dust'] = 2.2*df_new['Al'] + 2.49*df_new['Si'] + 1.63*df_new['Ca'] + 1.94*df_new['Ti'] + 2.42*df_new['Fe']\n",
    "        else:\n",
    "            df_new = df_imp.dropna(subset = [sp] + feature_list)\n",
    "        ## HANDLE OUTLIERS ##\n",
    "        outlier_cutoff = 3 * np.percentile(df_new[sp], 75)\n",
    "        num_non = df_new.shape[0]\n",
    "        df_new = df_new[df_new[sp] <= outlier_cutoff]\n",
    "        print(\"Outliers removed: \", num_non-df_new.shape[0])\n",
    "        print(\"Cutoff: \", outlier_cutoff)\n",
    "        ####\n",
    "        y = np.log(1 + df_new[sp])    \n",
    "        # y = df_new[sp]\n",
    "        X_train, X_test, _, y_train, y_test = transform(df_new[feature_list], None, None, y, \\\n",
    "            one_hot_cols = ['POC', 'fire_dist_25', 'ecosys'], split=True, exp_type=exp_type)\n",
    "        mod = RandomForestRegressor()\n",
    "        mod.fit(X_train, y_train)\n",
    "        preds = mod.predict(X_test)\n",
    "        mod2 = xgb.XGBRegressor(objective=\"reg:squarederror\")\n",
    "        mod2.fit(X_train, y_train)\n",
    "        preds2 = mod2.predict(X_test)\n",
    "\n",
    "        rmse_rf, r2_rf = get_perf(y_test, preds)\n",
    "        rmse_xg, r2_xg = get_perf(y_test, preds2)\n",
    "        res_imp = pd.concat([res_imp, pd.DataFrame({'species': [sp, sp], 'r2':[r2_rf, r2_xg], 'rmse': [rmse_rf, rmse_xg], \\\n",
    "            'imp_method': ['imp', 'imp'], 'model': ['rf', 'xgb'], 'test_set': ['imp', 'imp']})])    \n",
    "        # plot_fitted(y_test, preds, \" \".join([\"Fitted vs True:\", sp, \"(RF)\"]), \"\".join([\"../img/imputed/wo-out/fitted/\", sp, \"-\", exp_type, \"-fitted_rf.png\"]))\n",
    "        # plot_imp(mod, MODEL_FEATS[exp_type], \"Ft Importance for \" + sp + \" [\" + exp_type + \"]\", \"\".join([\"../img/imputed/wo-out/ft-imp/\", sp, \"-\", exp_type, \"-ft_imp_rf.png\"]))\n",
    "    return res_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AOD Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for experiment\n",
    "exp_type = 'aod_only'\n",
    "feature_list = subset_features+ADD_FEATS[exp_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BASE MODEL ###\n",
    "results_base_aod = pd.DataFrame({'species': [], 'r2':[], 'rmse': [], 'model': [], 'imp_method': [], 'test_set': []})\n",
    "results_base_aod = run_base(aod_df.dropna(subset=ADD_FEATS[exp_type]), df_imp_aod.iloc[list(set(aod_imp_ind))], feature_list, results_base_aod)\n",
    "results_base_aod.to_csv(\"results/results_base_aod.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPUTED MODEL ###\n",
    "results_imp_aod = pd.DataFrame({'species': [], 'r2':[], 'rmse': [], 'model': [], 'imp_method': [], 'test_set': []})\n",
    "results_imp_aod = run_imp(df_imp_aod, feature_list, results_imp_aod, exp_type)\n",
    "results_imp_aod.to_csv(\"results/results_imp_aod.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('pm25_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fac67311b4cc10997fea86fc0b9eb288af40e01f124fdfff4a14908eb39f0c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
